# -*- coding: utf-8 -*-
"""Predicting_Income_Level.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L46-OK1ouD8YYwLhN_qwyvSES-dElRum

# Machine Learning Assignment

##### Import libraries
"""

import numpy as np
import pandas as pd
import csv
import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_score, KFold
from sklearn.ensemble import RandomForestClassifier
from tqdm import tqdm

"""##### Load datasets"""

# Show all rows of dataframe
pd.set_option('display.max_rows', None)

# Load codebook
codebook = pd.read_csv('codebook.csv')
codebook

# Load test and train dataset
test = pd.read_csv('test.csv')
train = pd.read_csv('train.csv')

# Separate training data into X and Y variables
y_train = train['target']
X_train = train.drop('target', axis=1)

X_train.head(5)

"""Note that standardizing and normalizing is not required for Random Forests

##### Train model
"""

# Initialize variables
oos_accuracies = {}
num_features = []

# Set up outer k-fold cross-validation
outer_kf = KFold(n_splits=5, shuffle=True, random_state=0)

# Define the hyperparameter grid to tune
hyperparams = {
    'n_estimators': [100, 300],
    'max_depth': [10, None],
    'min_samples_split': [2, 10],
    'min_samples_leaf': [1, 5],
    'max_features': ['sqrt']  # Tried log2 but gave the same results
}

# Define additional model settings
criterion = 'entropy'
f_i_threshold = 0.010  # Importance threshold for the features

# Create and open a CSV file to store the results
csv_file = open('oos_accuracies.csv', mode='w', newline='')
csv_writer = csv.writer(csv_file)

# Write the header for the CSV file
csv_writer.writerow(['fold', 'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features', 'num_features', 'oos_accuracy'])

# Nested cross-validation with tqdm for progress
for cross_val_index, (train_index, test_index) in enumerate(tqdm(outer_kf.split(X_train), desc="Outer CV", total=outer_kf.get_n_splits()), 1):
    X_train_fold, X_test_fold = X_train.iloc[train_index], X_train.iloc[test_index]
    y_train_fold, y_test_fold = y_train.iloc[train_index], y_train.iloc[test_index]

    # Fit Random Forest on the training fold
    rf = RandomForestClassifier(random_state=0)
    rf.fit(X_train_fold, y_train_fold)

    # Get the features and their importance scores
    features = X_train_fold.columns
    f_i = list(zip(features, rf.feature_importances_))

    # Filter features with importance > f_i_threshold
    important_features = [(feature, importance) for feature, importance in f_i if importance > f_i_threshold]

    # Sort important features by importance, in descending order
    important_features.sort(key=lambda x: x[1], reverse=True)
    important_features_names = [feature[0] for feature in important_features]

    # Iterate over the number of important features
    for i in tqdm(range(25, len(important_features) + 1), desc="Evaluating features", leave=False):
        # Select the top i features
        selected_features = [f[0] for f in important_features[:i]]
        # Create a new dataframe with selected features
        X_selected = X_train_fold[selected_features]
        # Iterate over each combination of hyperparameters
        for n_estimators in hyperparams['n_estimators']:
            for max_depth in hyperparams['max_depth']:
                for min_samples_split in hyperparams['min_samples_split']:
                    for min_samples_leaf in hyperparams['min_samples_leaf']:
                        for max_features in hyperparams['max_features']:
                            # Define the model with current hyperparameter settings
                            rf = RandomForestClassifier(n_estimators=n_estimators,
                                                        max_depth=max_depth,
                                                        min_samples_split=min_samples_split,
                                                        min_samples_leaf=min_samples_leaf,
                                                        max_features=max_features,
                                                        random_state=0,
                                                        criterion=criterion)

                            # Compute OOS accuracy using cross-validation on the outer fold
                            scores = cross_val_score(rf, X_selected, y_train_fold, cv=5, scoring='accuracy')

                            # Write result to csv
                            csv_writer.writerow([cross_val_index, n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features, i, np.mean(scores)])

csv_file.close()

"""##### Visualize tuning results"""

# Read results file
results = pd.read_csv('oos_accuracies_result.csv')

# Drop max_features column (didn't tune in the end)
results = results.drop(['max_features'], axis=1)

# Replace NaN in max_depth (gives problems in aggregation)
results['max_depth'] = results['max_depth'].fillna("NaN")

# Define hyperparameter columns
hyperparameters = ['num_features', 'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf']

# Aggregate the folds, computing the mean oos_accuracy
results = results.groupby(hyperparameters).agg({'oos_accuracy': 'mean'}).reset_index()
results

# Create unique combinations of the 4 hyperparameters
results['hyperparam_combo'] = results.apply(lambda row: f"n_estimators={row['n_estimators']}, max_depth={row['max_depth']}, min_samples_split={row['min_samples_split']}, min_samples_leaf={row['min_samples_leaf']}", axis=1)

# Plot the accuracy with num_features on the x-axis and the combination of 4 hyperparameters in color
plt.figure(figsize=(10, 6))

# Use a colormap for the combinations of 4 hyperparameters
unique_combos = results['hyperparam_combo'].unique()
colors = plt.cm.viridis(np.linspace(0, 1, len(unique_combos)))

# Plot each unique combination
for i, combo in enumerate(unique_combos):
    subset = results[results['hyperparam_combo'] == combo]
    plt.plot(subset['num_features'], subset['oos_accuracy'], color=colors[i], label=combo, marker='o')

# Plot graph
plt.xlabel('Number of Features')
plt.ylabel('Mean Accuracy')
plt.title('Mean Accuracy for Different Hyperparameter Combinations')
plt.legend(title='Hyperparameters', bbox_to_anchor=(0.5, -0.2), loc='upper center', fontsize=8, ncol=2)
plt.tight_layout()
plt.savefig('mean_accuracy_hyperparameters.png', dpi=300, bbox_inches='tight')
plt.show()

"""##### Predict"""

# Fit Random Forest on full training sample
rf = RandomForestClassifier(random_state=0)
rf.fit(X_train,y_train)

# Get the features and their importance scores
features = X_train.columns
f_i = list(zip(features, rf.feature_importances_))

# Sort important features by importance
f_i.sort(key=lambda x: x[1], reverse=True)

# Filter features up to 32
f_i = f_i[:32]

# Create the bar plot for important features
plt.barh([x[0] for x in f_i], [x[1] for x in f_i])
plt.xlabel('Feature Importance')
plt.title('Features')
plt.gca().invert_yaxis()
plt.savefig('features_prediction.png', dpi=300, bbox_inches='tight')
plt.show()

# Unzip feature names to filter columns
feature_names, feature_importances = zip(*f_i)

# Define rf with hyperparameters and features
X_train = X_train[list(feature_names)]
rf = RandomForestClassifier(n_estimators=300,
                            max_depth=None,
                            min_samples_split=2,
                            min_samples_leaf=1,
                            max_features='sqrt',
                            random_state=0,
                            criterion='entropy')

# Fit rf with entire training sample
rf.fit(X_train,y_train)

# Reduce test data to 32 most important features from X_train
test = test[list(feature_names)]

# Predict y
y_pred = rf.predict(test)
print(y_pred)

# Write predictions to txt file
with open('predictions.txt', 'w') as file:
    file.write(' '.join(map(str, y_pred)))